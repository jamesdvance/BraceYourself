{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamesdvance/BraceYourself/blob/main/SAM_Personalize_One_Shot_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohuMqL1XjQ85"
      },
      "source": [
        "\n",
        "### SAM Personalize\n",
        "Using mobileSAM\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPdDUqd-hX-d",
        "outputId": "cf3c0a20-4f6d-4101-ada4-772c67a71c07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/ChaoningZhang/MobileSAM.git\n",
            "  Cloning https://github.com/ChaoningZhang/MobileSAM.git to /tmp/pip-req-build-55pvuolf\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/ChaoningZhang/MobileSAM.git /tmp/pip-req-build-55pvuolf\n",
            "  Resolved https://github.com/ChaoningZhang/MobileSAM.git to commit 01ea8d0f5590082f0c1ceb0a3e2272593f20154b\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mobile-sam\n",
            "  Building wheel for mobile-sam (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mobile-sam: filename=mobile_sam-1.0-py3-none-any.whl size=42432 sha256=c7a85ff331f26e5fa4973d07a1b06449eecfcc534cacf946c1c2884ad695fd9a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-kgw9u_vk/wheels/43/b1/9d/1c1b33c31d4c54f0a502f9c48b655f87213ab01e55d09cf4ef\n",
            "Successfully built mobile-sam\n",
            "Installing collected packages: mobile-sam\n",
            "Successfully installed mobile-sam-1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/ChaoningZhang/MobileSAM.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzZ4s8CfmlQ9",
        "outputId": "e6c0684c-087a-4322-a080-27ef2a543bfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'MobileSAM'...\n",
            "remote: Enumerating objects: 659, done.\u001b[K\n",
            "remote: Counting objects: 100% (288/288), done.\u001b[K\n",
            "remote: Compressing objects: 100% (100/100), done.\u001b[K\n",
            "remote: Total 659 (delta 252), reused 200 (delta 188), pack-reused 371\u001b[K\n",
            "Receiving objects: 100% (659/659), 78.90 MiB | 26.41 MiB/s, done.\n",
            "Resolving deltas: 100% (356/356), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/ChaoningZhang/MobileSAM.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJU7xXpdkBaT",
        "outputId": "cf6cddc9-39d1-44a6-d5c7-2c2b13d55465"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.9.8-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.16.0+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Collecting huggingface-hub (from timm)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors (from timm)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: safetensors, huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.18.0 safetensors-0.4.0 timm-0.9.8\n"
          ]
        }
      ],
      "source": [
        "! pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIA-_4HClDjO"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-d7DfK_mI0k"
      },
      "outputs": [],
      "source": [
        "from mobile_sam import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCVEIlZBmQ1P",
        "outputId": "d92f646d-c3fe-498d-ee2d-e862b89d7156"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MyDrive\n"
          ]
        }
      ],
      "source": [
        "! ls drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2Z3xuw9ltnz",
        "outputId": "efca0acb-0a65-4248-d57d-71d0b233ef09"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sam(\n",
              "  (image_encoder): TinyViT(\n",
              "    (patch_embed): PatchEmbed(\n",
              "      (seq): Sequential(\n",
              "        (0): Conv2d_BN(\n",
              "          (c): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Conv2d_BN(\n",
              "          (c): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layers): ModuleList(\n",
              "      (0): ConvLayer(\n",
              "        (blocks): ModuleList(\n",
              "          (0-1): 2 x MBConv(\n",
              "            (conv1): Conv2d_BN(\n",
              "              (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (act1): GELU(approximate='none')\n",
              "            (conv2): Conv2d_BN(\n",
              "              (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
              "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (act2): GELU(approximate='none')\n",
              "            (conv3): Conv2d_BN(\n",
              "              (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (act3): GELU(approximate='none')\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "        )\n",
              "        (downsample): PatchMerging(\n",
              "          (act): GELU(approximate='none')\n",
              "          (conv1): Conv2d_BN(\n",
              "            (c): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (conv2): Conv2d_BN(\n",
              "            (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (conv3): Conv2d_BN(\n",
              "            (c): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): BasicLayer(\n",
              "        dim=128, input_resolution=(128, 128), depth=2\n",
              "        (blocks): ModuleList(\n",
              "          (0-1): 2 x TinyViTBlock(\n",
              "            dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0\n",
              "            (drop_path): Identity()\n",
              "            (attn): Attention(\n",
              "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "              (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
              "              (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "            )\n",
              "            (mlp): Mlp(\n",
              "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
              "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (local_conv): Conv2d_BN(\n",
              "              (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (downsample): PatchMerging(\n",
              "          (act): GELU(approximate='none')\n",
              "          (conv1): Conv2d_BN(\n",
              "            (c): Conv2d(128, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (conv2): Conv2d_BN(\n",
              "            (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)\n",
              "            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (conv3): Conv2d_BN(\n",
              "            (c): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): BasicLayer(\n",
              "        dim=160, input_resolution=(64, 64), depth=6\n",
              "        (blocks): ModuleList(\n",
              "          (0-5): 6 x TinyViTBlock(\n",
              "            dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0\n",
              "            (drop_path): Identity()\n",
              "            (attn): Attention(\n",
              "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
              "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
              "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
              "            )\n",
              "            (mlp): Mlp(\n",
              "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
              "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
              "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (local_conv): Conv2d_BN(\n",
              "              (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
              "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (downsample): PatchMerging(\n",
              "          (act): GELU(approximate='none')\n",
              "          (conv1): Conv2d_BN(\n",
              "            (c): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (conv2): Conv2d_BN(\n",
              "            (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
              "            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (conv3): Conv2d_BN(\n",
              "            (c): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): BasicLayer(\n",
              "        dim=320, input_resolution=(64, 64), depth=2\n",
              "        (blocks): ModuleList(\n",
              "          (0-1): 2 x TinyViTBlock(\n",
              "            dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0\n",
              "            (drop_path): Identity()\n",
              "            (attn): Attention(\n",
              "              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
              "              (qkv): Linear(in_features=320, out_features=960, bias=True)\n",
              "              (proj): Linear(in_features=320, out_features=320, bias=True)\n",
              "            )\n",
              "            (mlp): Mlp(\n",
              "              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
              "              (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
              "              (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (local_conv): Conv2d_BN(\n",
              "              (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
              "              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (norm_head): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
              "    (head): Linear(in_features=320, out_features=1000, bias=True)\n",
              "    (neck): Sequential(\n",
              "      (0): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): LayerNorm2d()\n",
              "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (3): LayerNorm2d()\n",
              "    )\n",
              "  )\n",
              "  (prompt_encoder): PromptEncoder(\n",
              "    (pe_layer): PositionEmbeddingRandom()\n",
              "    (point_embeddings): ModuleList(\n",
              "      (0-3): 4 x Embedding(1, 256)\n",
              "    )\n",
              "    (not_a_point_embed): Embedding(1, 256)\n",
              "    (mask_downscaling): Sequential(\n",
              "      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))\n",
              "      (1): LayerNorm2d()\n",
              "      (2): GELU(approximate='none')\n",
              "      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))\n",
              "      (4): LayerNorm2d()\n",
              "      (5): GELU(approximate='none')\n",
              "      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (no_mask_embed): Embedding(1, 256)\n",
              "  )\n",
              "  (mask_decoder): MaskDecoder(\n",
              "    (transformer): TwoWayTransformer(\n",
              "      (layers): ModuleList(\n",
              "        (0-1): 2 x TwoWayAttentionBlock(\n",
              "          (self_attn): Attention(\n",
              "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "          (cross_attn_token_to_image): Attention(\n",
              "            (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "            (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "            (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "            (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
              "          )\n",
              "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): MLPBlock(\n",
              "            (lin1): Linear(in_features=256, out_features=2048, bias=True)\n",
              "            (lin2): Linear(in_features=2048, out_features=256, bias=True)\n",
              "            (act): ReLU()\n",
              "          )\n",
              "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "          (cross_attn_image_to_token): Attention(\n",
              "            (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "            (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "            (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "            (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_attn_token_to_image): Attention(\n",
              "        (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "        (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "        (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "        (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
              "      )\n",
              "      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (iou_token): Embedding(1, 256)\n",
              "    (mask_tokens): Embedding(4, 256)\n",
              "    (output_upscaling): Sequential(\n",
              "      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))\n",
              "      (1): LayerNorm2d()\n",
              "      (2): GELU(approximate='none')\n",
              "      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
              "      (4): GELU(approximate='none')\n",
              "    )\n",
              "    (output_hypernetworks_mlps): ModuleList(\n",
              "      (0-3): 4 x MLP(\n",
              "        (layers): ModuleList(\n",
              "          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
              "          (2): Linear(in_features=256, out_features=32, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (iou_prediction_head): MLP(\n",
              "      (layers): ModuleList(\n",
              "        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
              "        (2): Linear(in_features=256, out_features=4, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_type = \"vit_t\"\n",
        "sam_checkpoint = \"./MobileSAM/weights/mobile_sam.pt\"\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "mobile_sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
        "mobile_sam.to(device=device)\n",
        "mobile_sam.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ga0UX53VlNDU"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread(\"drive/MyDrive/braces_and_teeth/teeth2/train/2001.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty76pqoslevQ"
      },
      "source": [
        "#### Generating All Masks (no prompts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tTuJ_UyxjhCI"
      },
      "outputs": [],
      "source": [
        "\n",
        "mask_generator = SamAutomaticMaskGenerator(mobile_sam)\n",
        "masks = mask_generator.generate(img)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BntBeSTAsTm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img[masks[0][\"segmentation\"]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9i_uB5jsTdr",
        "outputId": "e9acc027-03fb-4145-dd29-ddde497b7811"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 50,  52,  96],\n",
              "       [ 46,  47,  89],\n",
              "       [ 40,  42,  81],\n",
              "       ...,\n",
              "       [136, 150, 179],\n",
              "       [134, 148, 176],\n",
              "       [134, 148, 177]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(img[masks[0][\"segmentation\"]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "Xn6c_ROSsFvO",
        "outputId": "a1c583ac-a16d-4fa8-f8f6-c79eeedef1f0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7a46f3c27eb0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uasieV6kJ15"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHSGYK1ekH3F"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1fhp5O8F9VnmV-rGgoySysOcEIJy28icq",
      "authorship_tag": "ABX9TyPC4qLwkFZhdwaLBN2FLUml",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}